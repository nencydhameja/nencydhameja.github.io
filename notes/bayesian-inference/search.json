[
  {
    "objectID": "bayes-theorem.html",
    "href": "bayes-theorem.html",
    "title": "Bayes’ Theorem",
    "section": "",
    "text": "\\[P(H \\mid D) = \\frac{P(D \\mid H) \\cdot P(H)}{P(D)}\\]\nIn words:\n\\[\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Evidence}}\\]\nThat looks abstract. Let’s make it concrete.",
    "crumbs": [
      "Bayes' Theorem"
    ]
  },
  {
    "objectID": "bayes-theorem.html#the-formula",
    "href": "bayes-theorem.html#the-formula",
    "title": "Bayes’ Theorem",
    "section": "",
    "text": "\\[P(H \\mid D) = \\frac{P(D \\mid H) \\cdot P(H)}{P(D)}\\]\nIn words:\n\\[\\text{Posterior} = \\frac{\\text{Likelihood} \\times \\text{Prior}}{\\text{Evidence}}\\]\nThat looks abstract. Let’s make it concrete.",
    "crumbs": [
      "Bayes' Theorem"
    ]
  },
  {
    "objectID": "bayes-theorem.html#the-medical-test-example",
    "href": "bayes-theorem.html#the-medical-test-example",
    "title": "Bayes’ Theorem",
    "section": "The medical test example",
    "text": "The medical test example\nImagine a disease that affects 1 in 1,000 people. A test for it is 99% accurate — if you have the disease it says positive 99% of the time, and if you don’t have it, it says negative 99% of the time.\nYou test positive. What’s the probability you actually have the disease?\nMost people say 99%. The real answer is about 9%. This is not a trick — it’s Bayes’ theorem. The disease is so rare that even a good test produces more false positives than true positives.\nThe simulator below lets you adjust the base rate and test accuracy and watch how the posterior probability changes.\n#| standalone: true\n#| viewerHeight: 580\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .result-box {\n      background: #f0f4f8; border-radius: 6px; padding: 16px;\n      margin-top: 14px; font-size: 15px; line-height: 2;\n      text-align: center;\n    }\n    .result-box .big {\n      font-size: 32px; color: #e74c3c; font-weight: bold;\n    }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"prev\", \"Base rate (prevalence):\",\n                  min = 0.001, max = 0.20, value = 0.001, step = 0.001),\n\n      sliderInput(\"sens\", \"Sensitivity (true positive rate):\",\n                  min = 0.50, max = 1.00, value = 0.99, step = 0.01),\n\n      sliderInput(\"spec\", \"Specificity (true negative rate):\",\n                  min = 0.50, max = 1.00, value = 0.99, step = 0.01),\n\n      uiOutput(\"result_box\")\n    ),\n\n    mainPanel(\n      width = 9,\n      fluidRow(\n        column(6, plotOutput(\"tree_plot\", height = \"420px\")),\n        column(6, plotOutput(\"icon_plot\", height = \"420px\"))\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  vals &lt;- reactive({\n    prev &lt;- input$prev\n    sens &lt;- input$sens\n    spec &lt;- input$spec\n\n    # Out of 10,000 people\n    N &lt;- 10000\n    sick &lt;- round(N * prev)\n    healthy &lt;- N - sick\n\n    true_pos  &lt;- round(sick * sens)\n    false_neg &lt;- sick - true_pos\n    false_pos &lt;- round(healthy * (1 - spec))\n    true_neg  &lt;- healthy - false_pos\n\n    total_pos &lt;- true_pos + false_pos\n    ppv &lt;- if (total_pos &gt; 0) true_pos / total_pos else 0\n\n    list(N = N, sick = sick, healthy = healthy,\n         true_pos = true_pos, false_neg = false_neg,\n         false_pos = false_pos, true_neg = true_neg,\n         total_pos = total_pos, ppv = ppv)\n  })\n\n  output$tree_plot &lt;- renderPlot({\n    v &lt;- vals()\n    par(mar = c(1, 1, 3, 1))\n\n    plot(NULL, xlim = c(0, 10), ylim = c(0, 10), axes = FALSE,\n         xlab = \"\", ylab = \"\", main = \"What happens to 10,000 people?\")\n\n    # Population\n    text(5, 9.5, paste0(\"Population: \", v$N), cex = 1.2, font = 2)\n\n    # Sick vs Healthy\n    text(2.5, 7.5, paste0(\"Sick: \", v$sick), cex = 1.1, col = \"#e74c3c\")\n    text(7.5, 7.5, paste0(\"Healthy: \", v$healthy), cex = 1.1, col = \"#3498db\")\n    segments(5, 9, 2.5, 8, lwd = 2)\n    segments(5, 9, 7.5, 8, lwd = 2)\n\n    # Test results for sick\n    text(1.2, 5.2, paste0(\"Test +\\n\", v$true_pos), cex = 1, col = \"#27ae60\", font = 2)\n    text(3.8, 5.2, paste0(\"Test -\\n\", v$false_neg), cex = 1, col = \"#7f8c8d\")\n    segments(2.5, 7, 1.2, 5.8, lwd = 1.5)\n    segments(2.5, 7, 3.8, 5.8, lwd = 1.5)\n\n    # Test results for healthy\n    text(6.2, 5.2, paste0(\"Test +\\n\", v$false_pos), cex = 1, col = \"#e74c3c\", font = 2)\n    text(8.8, 5.2, paste0(\"Test -\\n\", v$true_neg), cex = 1, col = \"#7f8c8d\")\n    segments(7.5, 7, 6.2, 5.8, lwd = 1.5)\n    segments(7.5, 7, 8.8, 5.8, lwd = 1.5)\n\n    # Total positives\n    text(3.7, 3, paste0(\"Total positive tests: \", v$total_pos), cex = 1.1, font = 2)\n    text(3.7, 2, paste0(\"Of these, truly sick: \", v$true_pos), cex = 1.1,\n         col = \"#27ae60\", font = 2)\n    text(3.7, 1, paste0(\"P(sick | test+) = \",\n         v$true_pos, \"/\", v$total_pos, \" = \",\n         round(v$ppv * 100, 1), \"%\"), cex = 1.2, font = 2, col = \"#e74c3c\")\n  })\n\n  output$icon_plot &lt;- renderPlot({\n    v &lt;- vals()\n    par(mar = c(1, 1, 3, 1))\n\n    # Show total positive tests as dots\n    n_show &lt;- min(v$total_pos, 200)\n    n_true &lt;- round(n_show * v$ppv)\n    n_false &lt;- n_show - n_true\n\n    cols &lt;- c(rep(\"#27ae60\", n_true), rep(\"#e74c3c\", n_false))\n    cols &lt;- sample(cols)\n\n    ncol &lt;- ceiling(sqrt(n_show))\n    nrow &lt;- ceiling(n_show / ncol)\n\n    plot(NULL, xlim = c(0, ncol + 1), ylim = c(0, nrow + 1),\n         axes = FALSE, xlab = \"\", ylab = \"\",\n         main = paste0(\"All \", v$total_pos, \" positive tests\"))\n\n    if (n_show &gt; 0) {\n      x &lt;- rep(seq_len(ncol), times = nrow)[seq_len(n_show)]\n      y &lt;- rep(seq(nrow, 1), each = ncol)[seq_len(n_show)]\n      points(x, y, pch = 15, cex = max(0.5, 3 - n_show / 50), col = cols)\n    }\n\n    legend(\"bottom\", bty = \"n\", horiz = TRUE, cex = 0.95,\n           legend = c(paste0(\"Truly sick (\", n_true, \")\"),\n                      paste0(\"False alarm (\", n_false, \")\")),\n           col = c(\"#27ae60\", \"#e74c3c\"), pch = 15, pt.cex = 1.5)\n  })\n\n  output$result_box &lt;- renderUI({\n    v &lt;- vals()\n    tags$div(class = \"result-box\",\n      HTML(paste0(\n        \"If you test positive,&lt;br&gt;\",\n        \"the probability you're sick is:&lt;br&gt;\",\n        \"&lt;span class='big'&gt;\", round(v$ppv * 100, 1), \"%&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;small&gt;not \", round(input$sens * 100), \"%!&lt;/small&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\nThings to try\n\nDefault settings (prevalence 0.1%, test 99% accurate): only ~9% of positive tests are truly sick. The base rate dominates.\nSlide prevalence up to 5%: now ~84% of positives are real. The prior matters!\nSlide prevalence to 50%: the posterior is ~99%. When the disease is common, a positive test is very informative.\nLower specificity to 90%: false positives explode. Watch the right plot fill with red dots.\n\n\n\nThe lesson\nBayes’ theorem tells you: don’t just look at the test accuracy — look at how common the thing is. A 99% accurate test is nearly useless for a 1-in-1,000 disease because most positives are false alarms. This is the base rate fallacy, and Bayes’ theorem is the cure.",
    "crumbs": [
      "Bayes' Theorem"
    ]
  },
  {
    "objectID": "priors-posteriors.html",
    "href": "priors-posteriors.html",
    "title": "Priors & Posteriors",
    "section": "",
    "text": "Imagine you’re trying to estimate something — say, the average effect of a tutoring program on test scores. In frequentist statistics, you collect data, compute a point estimate, and that’s your answer.\nIn Bayesian statistics, you do something different:\n\nStart with a prior — what you believed before seeing data. Maybe from past studies, expert opinion, or just “I have no idea” (a flat prior).\nObserve data — the likelihood tells you how probable the data is for each possible value of the parameter.\nCombine them — Bayes’ theorem multiplies the prior by the likelihood to give you the posterior: your updated belief after seeing the data.\n\n\\[\\underbrace{P(\\theta \\mid \\text{data})}_{\\text{posterior}} \\propto \\underbrace{P(\\text{data} \\mid \\theta)}_{\\text{likelihood}} \\times \\underbrace{P(\\theta)}_{\\text{prior}}\\]\nThe simulation below makes this tangible. You’re estimating the true mean of a normal distribution. Set a prior, generate data, and watch the posterior form.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"true_mu\", HTML(\"True &mu; (unknown to you):\"),\n                  min = -5, max = 5, value = 2, step = 0.5),\n\n      sliderInput(\"prior_mu\", \"Prior mean:\",\n                  min = -5, max = 5, value = 0, step = 0.5),\n\n      sliderInput(\"prior_sd\", \"Prior SD (certainty):\",\n                  min = 0.5, max = 10, value = 3, step = 0.5),\n\n      sliderInput(\"n\", \"Sample size (data):\",\n                  min = 1, max = 200, value = 5, step = 1),\n\n      sliderInput(\"sigma\", HTML(\"Data noise (&sigma;):\"),\n                  min = 0.5, max = 5, value = 2, step = 0.5),\n\n      actionButton(\"go\", \"New draw\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      plotOutput(\"posterior_plot\", height = \"450px\")\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n\n    true_mu  &lt;- input$true_mu\n    prior_mu &lt;- input$prior_mu\n    prior_sd &lt;- input$prior_sd\n    n        &lt;- input$n\n    sigma    &lt;- input$sigma\n\n    # Generate data\n    y &lt;- rnorm(n, mean = true_mu, sd = sigma)\n    y_bar &lt;- mean(y)\n\n    # Posterior (conjugate normal-normal)\n    prior_prec &lt;- 1 / prior_sd^2\n    data_prec  &lt;- n / sigma^2\n    post_prec  &lt;- prior_prec + data_prec\n    post_sd    &lt;- 1 / sqrt(post_prec)\n    post_mu    &lt;- (prior_prec * prior_mu + data_prec * y_bar) / post_prec\n\n    # Shrinkage weight on prior\n    w_prior &lt;- prior_prec / post_prec\n\n    list(true_mu = true_mu, prior_mu = prior_mu, prior_sd = prior_sd,\n         y_bar = y_bar, sigma = sigma, n = n,\n         post_mu = post_mu, post_sd = post_sd, w_prior = w_prior)\n  })\n\n  output$posterior_plot &lt;- renderPlot({\n    d &lt;- dat()\n\n    xmin &lt;- min(d$prior_mu - 3.5 * d$prior_sd, d$post_mu - 4 * d$post_sd, d$true_mu - 2)\n    xmax &lt;- max(d$prior_mu + 3.5 * d$prior_sd, d$post_mu + 4 * d$post_sd, d$true_mu + 2)\n    x &lt;- seq(xmin, xmax, length.out = 500)\n\n    y_prior &lt;- dnorm(x, d$prior_mu, d$prior_sd)\n    y_like  &lt;- dnorm(x, d$y_bar, d$sigma / sqrt(d$n))\n    y_post  &lt;- dnorm(x, d$post_mu, d$post_sd)\n\n    ylim &lt;- c(0, max(y_prior, y_like, y_post) * 1.15)\n\n    par(mar = c(4.5, 4.5, 3, 1))\n    plot(x, y_prior, type = \"l\", lwd = 2.5, col = \"#e74c3c\",\n         xlab = expression(mu), ylab = \"Density\",\n         main = \"Prior + Likelihood = Posterior\",\n         ylim = ylim)\n    lines(x, y_like, lwd = 2.5, col = \"#3498db\")\n    lines(x, y_post, lwd = 3, col = \"#27ae60\")\n\n    # Shade posterior\n    polygon(c(x, rev(x)),\n            c(y_post, rep(0, length(x))),\n            col = adjustcolor(\"#27ae60\", 0.2), border = NA)\n\n    # True value\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n\n    legend(\"topright\", bty = \"n\", cex = 0.9,\n           legend = c(\"Prior (your belief before data)\",\n                      \"Likelihood (what the data says)\",\n                      \"Posterior (updated belief)\",\n                      expression(\"True \" * mu)),\n           col = c(\"#e74c3c\", \"#3498db\", \"#27ae60\", \"#2c3e50\"),\n           lwd = c(2.5, 2.5, 3, 2),\n           lty = c(1, 1, 1, 2))\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Prior mean:&lt;/b&gt; \", d$prior_mu, \"&lt;br&gt;\",\n        \"&lt;b&gt;Data mean:&lt;/b&gt; \", round(d$y_bar, 3), \"&lt;br&gt;\",\n        \"&lt;b&gt;Posterior mean:&lt;/b&gt; \", round(d$post_mu, 3), \"&lt;br&gt;\",\n        \"&lt;b&gt;Posterior SD:&lt;/b&gt; \", round(d$post_sd, 3), \"&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Weight on prior:&lt;/b&gt; \", round(d$w_prior * 100, 1), \"%&lt;br&gt;\",\n        \"&lt;b&gt;Weight on data:&lt;/b&gt; \", round((1 - d$w_prior) * 100, 1), \"%&lt;br&gt;\",\n        \"&lt;small&gt;Posterior = weighted average of prior & data&lt;/small&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\nn = 1: the posterior is mostly the prior (red). You barely have data.\nSlide n to 100: the posterior (green) collapses onto the data mean (blue). Data overwhelms the prior. With enough data, the prior doesn’t matter.\nSet prior SD = 0.5 (strong prior) with n = 5: the posterior is pulled toward the prior. This is shrinkage — the prior is “shrinking” your estimate away from the data and toward your prior belief.\nSet prior SD = 10 (vague prior): the posterior tracks the data almost exactly. A flat prior says “I have no opinion” and lets the data speak.\nWatch the weight on prior in the sidebar — it shows exactly how much the posterior is a compromise between prior and data.",
    "crumbs": [
      "Priors & Posteriors"
    ]
  },
  {
    "objectID": "priors-posteriors.html#what-is-bayesian-inference-really",
    "href": "priors-posteriors.html#what-is-bayesian-inference-really",
    "title": "Priors & Posteriors",
    "section": "",
    "text": "Imagine you’re trying to estimate something — say, the average effect of a tutoring program on test scores. In frequentist statistics, you collect data, compute a point estimate, and that’s your answer.\nIn Bayesian statistics, you do something different:\n\nStart with a prior — what you believed before seeing data. Maybe from past studies, expert opinion, or just “I have no idea” (a flat prior).\nObserve data — the likelihood tells you how probable the data is for each possible value of the parameter.\nCombine them — Bayes’ theorem multiplies the prior by the likelihood to give you the posterior: your updated belief after seeing the data.\n\n\\[\\underbrace{P(\\theta \\mid \\text{data})}_{\\text{posterior}} \\propto \\underbrace{P(\\text{data} \\mid \\theta)}_{\\text{likelihood}} \\times \\underbrace{P(\\theta)}_{\\text{prior}}\\]\nThe simulation below makes this tangible. You’re estimating the true mean of a normal distribution. Set a prior, generate data, and watch the posterior form.\n#| standalone: true\n#| viewerHeight: 600\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"true_mu\", HTML(\"True &mu; (unknown to you):\"),\n                  min = -5, max = 5, value = 2, step = 0.5),\n\n      sliderInput(\"prior_mu\", \"Prior mean:\",\n                  min = -5, max = 5, value = 0, step = 0.5),\n\n      sliderInput(\"prior_sd\", \"Prior SD (certainty):\",\n                  min = 0.5, max = 10, value = 3, step = 0.5),\n\n      sliderInput(\"n\", \"Sample size (data):\",\n                  min = 1, max = 200, value = 5, step = 1),\n\n      sliderInput(\"sigma\", HTML(\"Data noise (&sigma;):\"),\n                  min = 0.5, max = 5, value = 2, step = 0.5),\n\n      actionButton(\"go\", \"New draw\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      plotOutput(\"posterior_plot\", height = \"450px\")\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n\n    true_mu  &lt;- input$true_mu\n    prior_mu &lt;- input$prior_mu\n    prior_sd &lt;- input$prior_sd\n    n        &lt;- input$n\n    sigma    &lt;- input$sigma\n\n    # Generate data\n    y &lt;- rnorm(n, mean = true_mu, sd = sigma)\n    y_bar &lt;- mean(y)\n\n    # Posterior (conjugate normal-normal)\n    prior_prec &lt;- 1 / prior_sd^2\n    data_prec  &lt;- n / sigma^2\n    post_prec  &lt;- prior_prec + data_prec\n    post_sd    &lt;- 1 / sqrt(post_prec)\n    post_mu    &lt;- (prior_prec * prior_mu + data_prec * y_bar) / post_prec\n\n    # Shrinkage weight on prior\n    w_prior &lt;- prior_prec / post_prec\n\n    list(true_mu = true_mu, prior_mu = prior_mu, prior_sd = prior_sd,\n         y_bar = y_bar, sigma = sigma, n = n,\n         post_mu = post_mu, post_sd = post_sd, w_prior = w_prior)\n  })\n\n  output$posterior_plot &lt;- renderPlot({\n    d &lt;- dat()\n\n    xmin &lt;- min(d$prior_mu - 3.5 * d$prior_sd, d$post_mu - 4 * d$post_sd, d$true_mu - 2)\n    xmax &lt;- max(d$prior_mu + 3.5 * d$prior_sd, d$post_mu + 4 * d$post_sd, d$true_mu + 2)\n    x &lt;- seq(xmin, xmax, length.out = 500)\n\n    y_prior &lt;- dnorm(x, d$prior_mu, d$prior_sd)\n    y_like  &lt;- dnorm(x, d$y_bar, d$sigma / sqrt(d$n))\n    y_post  &lt;- dnorm(x, d$post_mu, d$post_sd)\n\n    ylim &lt;- c(0, max(y_prior, y_like, y_post) * 1.15)\n\n    par(mar = c(4.5, 4.5, 3, 1))\n    plot(x, y_prior, type = \"l\", lwd = 2.5, col = \"#e74c3c\",\n         xlab = expression(mu), ylab = \"Density\",\n         main = \"Prior + Likelihood = Posterior\",\n         ylim = ylim)\n    lines(x, y_like, lwd = 2.5, col = \"#3498db\")\n    lines(x, y_post, lwd = 3, col = \"#27ae60\")\n\n    # Shade posterior\n    polygon(c(x, rev(x)),\n            c(y_post, rep(0, length(x))),\n            col = adjustcolor(\"#27ae60\", 0.2), border = NA)\n\n    # True value\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n\n    legend(\"topright\", bty = \"n\", cex = 0.9,\n           legend = c(\"Prior (your belief before data)\",\n                      \"Likelihood (what the data says)\",\n                      \"Posterior (updated belief)\",\n                      expression(\"True \" * mu)),\n           col = c(\"#e74c3c\", \"#3498db\", \"#27ae60\", \"#2c3e50\"),\n           lwd = c(2.5, 2.5, 3, 2),\n           lty = c(1, 1, 1, 2))\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Prior mean:&lt;/b&gt; \", d$prior_mu, \"&lt;br&gt;\",\n        \"&lt;b&gt;Data mean:&lt;/b&gt; \", round(d$y_bar, 3), \"&lt;br&gt;\",\n        \"&lt;b&gt;Posterior mean:&lt;/b&gt; \", round(d$post_mu, 3), \"&lt;br&gt;\",\n        \"&lt;b&gt;Posterior SD:&lt;/b&gt; \", round(d$post_sd, 3), \"&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Weight on prior:&lt;/b&gt; \", round(d$w_prior * 100, 1), \"%&lt;br&gt;\",\n        \"&lt;b&gt;Weight on data:&lt;/b&gt; \", round((1 - d$w_prior) * 100, 1), \"%&lt;br&gt;\",\n        \"&lt;small&gt;Posterior = weighted average of prior & data&lt;/small&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\nn = 1: the posterior is mostly the prior (red). You barely have data.\nSlide n to 100: the posterior (green) collapses onto the data mean (blue). Data overwhelms the prior. With enough data, the prior doesn’t matter.\nSet prior SD = 0.5 (strong prior) with n = 5: the posterior is pulled toward the prior. This is shrinkage — the prior is “shrinking” your estimate away from the data and toward your prior belief.\nSet prior SD = 10 (vague prior): the posterior tracks the data almost exactly. A flat prior says “I have no opinion” and lets the data speak.\nWatch the weight on prior in the sidebar — it shows exactly how much the posterior is a compromise between prior and data.",
    "crumbs": [
      "Priors & Posteriors"
    ]
  },
  {
    "objectID": "priors-posteriors.html#shrinkage-the-bayesian-superpower",
    "href": "priors-posteriors.html#shrinkage-the-bayesian-superpower",
    "title": "Priors & Posteriors",
    "section": "Shrinkage: the Bayesian superpower",
    "text": "Shrinkage: the Bayesian superpower\nLook at the “weight on prior” number in the sidebar. The posterior mean is literally a weighted average:\n\\[\\mu_{post} = w \\cdot \\mu_{prior} + (1 - w) \\cdot \\bar{y}\\]\nwhere \\(w\\) depends on how confident your prior is relative to how much data you have.\nThis is shrinkage: the posterior “shrinks” the data estimate toward the prior. When is this useful?\n\nSmall samples: noisy data gets regularized toward a sensible default.\nMany groups: estimating batting averages for 500 baseball players? Shrink extreme estimates toward the league average. A player who went 3-for-3 on opening day probably isn’t a .1000 hitter.\nHierarchical models: borrow strength across groups by shrinking toward a common mean.\n\nShrinkage isn’t bias — it’s a bias-variance tradeoff. You add a little bias but reduce variance a lot, often improving overall accuracy.",
    "crumbs": [
      "Priors & Posteriors"
    ]
  },
  {
    "objectID": "bayes-vs-freq.html",
    "href": "bayes-vs-freq.html",
    "title": "Bayesian vs Frequentist",
    "section": "",
    "text": "Bayesian and frequentist statistics look at the same data but ask different questions:\n\n\n\n\n\n\n\n\n\nFrequentist\nBayesian\n\n\n\n\nParameters are…\nFixed but unknown\nRandom variables with distributions\n\n\nProbability means…\nLong-run frequency\nDegree of belief\n\n\nResult\nPoint estimate + confidence interval\nFull posterior distribution\n\n\n“There’s a 95% chance…”\n…that this procedure captures the true value\n…that the true value is in this interval\n\n\n\nThe frequentist says: “If I repeated this experiment forever, 95% of my CIs would contain the true value.” The Bayesian says: “Given what I’ve seen, I’m 95% sure the true value is in this range.”\nMost people actually think like Bayesians (“what’s the probability the parameter is between A and B?”) but compute like frequentists (p-values, CIs).\n\n\nThe simulation below runs the same experiment and shows both the frequentist confidence interval and the Bayesian credible interval. Watch how they differ — especially with small samples and informative priors.\n#| standalone: true\n#| viewerHeight: 620\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"true_mu\", HTML(\"True &mu;:\"),\n                  min = -3, max = 3, value = 1, step = 0.5),\n\n      sliderInput(\"n\", \"Sample size:\",\n                  min = 2, max = 200, value = 10, step = 1),\n\n      sliderInput(\"prior_mu\", \"Bayesian prior mean:\",\n                  min = -3, max = 3, value = 0, step = 0.5),\n\n      sliderInput(\"prior_sd\", \"Prior SD:\",\n                  min = 0.5, max = 10, value = 2, step = 0.5),\n\n      actionButton(\"go\", \"New experiment\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      fluidRow(\n        column(6, plotOutput(\"interval_plot\", height = \"420px\")),\n        column(6, plotOutput(\"repeat_plot\",   height = \"420px\"))\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n    true_mu  &lt;- input$true_mu\n    n        &lt;- input$n\n    prior_mu &lt;- input$prior_mu\n    prior_sd &lt;- input$prior_sd\n    sigma    &lt;- 2\n\n    y &lt;- rnorm(n, mean = true_mu, sd = sigma)\n    y_bar &lt;- mean(y)\n    se &lt;- sigma / sqrt(n)\n\n    # Frequentist 95% CI\n    freq_lo &lt;- y_bar - 1.96 * se\n    freq_hi &lt;- y_bar + 1.96 * se\n\n    # Bayesian posterior\n    prior_prec &lt;- 1 / prior_sd^2\n    data_prec  &lt;- n / sigma^2\n    post_prec  &lt;- prior_prec + data_prec\n    post_sd    &lt;- 1 / sqrt(post_prec)\n    post_mu    &lt;- (prior_prec * prior_mu + data_prec * y_bar) / post_prec\n\n    bayes_lo &lt;- qnorm(0.025, post_mu, post_sd)\n    bayes_hi &lt;- qnorm(0.975, post_mu, post_sd)\n\n    # Repeated experiments for right panel\n    k &lt;- 50\n    reps &lt;- t(replicate(k, {\n      yy &lt;- rnorm(n, mean = true_mu, sd = sigma)\n      yy_bar &lt;- mean(yy)\n      f_lo &lt;- yy_bar - 1.96 * se\n      f_hi &lt;- yy_bar + 1.96 * se\n\n      d_prec &lt;- n / sigma^2\n      p_prec &lt;- prior_prec + d_prec\n      p_sd &lt;- 1 / sqrt(p_prec)\n      p_mu &lt;- (prior_prec * prior_mu + d_prec * yy_bar) / p_prec\n      b_lo &lt;- qnorm(0.025, p_mu, p_sd)\n      b_hi &lt;- qnorm(0.975, p_mu, p_sd)\n\n      c(yy_bar, f_lo, f_hi, p_mu, b_lo, b_hi)\n    }))\n\n    list(true_mu = true_mu, y_bar = y_bar,\n         freq_lo = freq_lo, freq_hi = freq_hi,\n         post_mu = post_mu, post_sd = post_sd,\n         bayes_lo = bayes_lo, bayes_hi = bayes_hi,\n         reps = reps, prior_mu = prior_mu)\n  })\n\n  output$interval_plot &lt;- renderPlot({\n    d &lt;- dat()\n\n    par(mar = c(4.5, 8, 3, 1))\n    xlim &lt;- range(c(d$freq_lo, d$freq_hi, d$bayes_lo, d$bayes_hi, d$true_mu)) +\n            c(-0.5, 0.5)\n\n    plot(NULL, xlim = xlim, ylim = c(0.5, 2.5),\n         yaxt = \"n\", ylab = \"\", xlab = expression(mu),\n         main = \"This Experiment\")\n    axis(2, at = 1:2, labels = c(\"Frequentist\\n95% CI\", \"Bayesian\\n95% CrI\"),\n         las = 1, cex.axis = 0.85)\n\n    # Frequentist\n    segments(d$freq_lo, 1, d$freq_hi, 1, lwd = 4, col = \"#e74c3c\")\n    points(d$y_bar, 1, pch = 19, cex = 1.5, col = \"#e74c3c\")\n\n    # Bayesian\n    segments(d$bayes_lo, 2, d$bayes_hi, 2, lwd = 4, col = \"#3498db\")\n    points(d$post_mu, 2, pch = 19, cex = 1.5, col = \"#3498db\")\n\n    # True value\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n    text(d$true_mu, 2.4, expression(\"True \" * mu), cex = 0.9, col = \"#2c3e50\")\n  })\n\n  output$repeat_plot &lt;- renderPlot({\n    d &lt;- dat()\n    k &lt;- nrow(d$reps)\n\n    par(mar = c(4.5, 4, 3, 1))\n\n    freq_covers &lt;- d$reps[, 2] &lt;= d$true_mu & d$reps[, 3] &gt;= d$true_mu\n    bayes_covers &lt;- d$reps[, 5] &lt;= d$true_mu & d$reps[, 6] &gt;= d$true_mu\n\n    xlim &lt;- range(d$reps[, 2:6], d$true_mu) + c(-0.5, 0.5)\n\n    plot(NULL, xlim = xlim, ylim = c(1, k),\n         xlab = expression(mu), ylab = \"Experiment #\",\n         main = paste0(k, \" repeated experiments\"))\n\n    for (i in seq_len(k)) {\n      # Frequentist (left-shifted slightly)\n      clr_f &lt;- if (freq_covers[i]) \"#e74c3c\" else \"#e74c3c40\"\n      segments(d$reps[i, 2], i - 0.15, d$reps[i, 3], i - 0.15,\n               lwd = 1.5, col = clr_f)\n\n      # Bayesian (right-shifted slightly)\n      clr_b &lt;- if (bayes_covers[i]) \"#3498db\" else \"#3498db40\"\n      segments(d$reps[i, 5], i + 0.15, d$reps[i, 6], i + 0.15,\n               lwd = 1.5, col = clr_b)\n    }\n\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n\n    legend(\"topright\", bty = \"n\", cex = 0.8,\n           legend = c(\n             paste0(\"Freq CI (\", sum(freq_covers), \"/\", k, \" cover)\"),\n             paste0(\"Bayes CrI (\", sum(bayes_covers), \"/\", k, \" cover)\")\n           ),\n           col = c(\"#e74c3c\", \"#3498db\"), lwd = 3)\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Frequentist:&lt;/b&gt;&lt;br&gt;\",\n        \"Estimate: \", round(d$y_bar, 3), \"&lt;br&gt;\",\n        \"95% CI: [\", round(d$freq_lo, 3), \", \", round(d$freq_hi, 3), \"]&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Bayesian:&lt;/b&gt;&lt;br&gt;\",\n        \"Posterior mean: \", round(d$post_mu, 3), \"&lt;br&gt;\",\n        \"95% CrI: [\", round(d$bayes_lo, 3), \", \", round(d$bayes_hi, 3), \"]&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;small&gt;CrI is narrower because the prior adds information.&lt;/small&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\n\nn = 5, prior centered at 0, true mu = 1: the Bayesian CrI is narrower but pulled toward 0 (shrinkage). The frequentist CI is wider but centered on the data.\nn = 200: both intervals are nearly identical. With lots of data, the prior washes out and Bayesian = frequentist.\nSet a wrong prior (prior mean = -3, true mu = 2, n = 5): the Bayesian interval gets pulled toward -3. A bad prior hurts with small samples. Slide n up — the data corrects it.\nRight panel: the frequentist CI is designed so that ~95% of the red intervals cover the truth across repetitions. The Bayesian CrI coverage depends on how good the prior is.\n\n\n\n\n\n\n\n\n\n\n\nUse frequentist when…\nUse Bayesian when…\n\n\n\n\nYou want procedure guarantees (coverage)\nYou want direct probability statements\n\n\nYou have no prior information\nYou have real prior knowledge\n\n\nRegulatory/peer review expects it\nSmall samples, need to borrow strength\n\n\nSimple problems\nComplex hierarchical models\n\n\n\nIn practice, most applied researchers use frequentist methods but interpret them like Bayesians. Understanding both helps you know what your numbers actually mean.",
    "crumbs": [
      "Bayesian vs Frequentist"
    ]
  },
  {
    "objectID": "bayes-vs-freq.html#same-data-different-questions",
    "href": "bayes-vs-freq.html#same-data-different-questions",
    "title": "Bayesian vs Frequentist",
    "section": "",
    "text": "Bayesian and frequentist statistics look at the same data but ask different questions:\n\n\n\n\n\n\n\n\n\nFrequentist\nBayesian\n\n\n\n\nParameters are…\nFixed but unknown\nRandom variables with distributions\n\n\nProbability means…\nLong-run frequency\nDegree of belief\n\n\nResult\nPoint estimate + confidence interval\nFull posterior distribution\n\n\n“There’s a 95% chance…”\n…that this procedure captures the true value\n…that the true value is in this interval\n\n\n\nThe frequentist says: “If I repeated this experiment forever, 95% of my CIs would contain the true value.” The Bayesian says: “Given what I’ve seen, I’m 95% sure the true value is in this range.”\nMost people actually think like Bayesians (“what’s the probability the parameter is between A and B?”) but compute like frequentists (p-values, CIs).\n\n\nThe simulation below runs the same experiment and shows both the frequentist confidence interval and the Bayesian credible interval. Watch how they differ — especially with small samples and informative priors.\n#| standalone: true\n#| viewerHeight: 620\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"true_mu\", HTML(\"True &mu;:\"),\n                  min = -3, max = 3, value = 1, step = 0.5),\n\n      sliderInput(\"n\", \"Sample size:\",\n                  min = 2, max = 200, value = 10, step = 1),\n\n      sliderInput(\"prior_mu\", \"Bayesian prior mean:\",\n                  min = -3, max = 3, value = 0, step = 0.5),\n\n      sliderInput(\"prior_sd\", \"Prior SD:\",\n                  min = 0.5, max = 10, value = 2, step = 0.5),\n\n      actionButton(\"go\", \"New experiment\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      fluidRow(\n        column(6, plotOutput(\"interval_plot\", height = \"420px\")),\n        column(6, plotOutput(\"repeat_plot\",   height = \"420px\"))\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n    true_mu  &lt;- input$true_mu\n    n        &lt;- input$n\n    prior_mu &lt;- input$prior_mu\n    prior_sd &lt;- input$prior_sd\n    sigma    &lt;- 2\n\n    y &lt;- rnorm(n, mean = true_mu, sd = sigma)\n    y_bar &lt;- mean(y)\n    se &lt;- sigma / sqrt(n)\n\n    # Frequentist 95% CI\n    freq_lo &lt;- y_bar - 1.96 * se\n    freq_hi &lt;- y_bar + 1.96 * se\n\n    # Bayesian posterior\n    prior_prec &lt;- 1 / prior_sd^2\n    data_prec  &lt;- n / sigma^2\n    post_prec  &lt;- prior_prec + data_prec\n    post_sd    &lt;- 1 / sqrt(post_prec)\n    post_mu    &lt;- (prior_prec * prior_mu + data_prec * y_bar) / post_prec\n\n    bayes_lo &lt;- qnorm(0.025, post_mu, post_sd)\n    bayes_hi &lt;- qnorm(0.975, post_mu, post_sd)\n\n    # Repeated experiments for right panel\n    k &lt;- 50\n    reps &lt;- t(replicate(k, {\n      yy &lt;- rnorm(n, mean = true_mu, sd = sigma)\n      yy_bar &lt;- mean(yy)\n      f_lo &lt;- yy_bar - 1.96 * se\n      f_hi &lt;- yy_bar + 1.96 * se\n\n      d_prec &lt;- n / sigma^2\n      p_prec &lt;- prior_prec + d_prec\n      p_sd &lt;- 1 / sqrt(p_prec)\n      p_mu &lt;- (prior_prec * prior_mu + d_prec * yy_bar) / p_prec\n      b_lo &lt;- qnorm(0.025, p_mu, p_sd)\n      b_hi &lt;- qnorm(0.975, p_mu, p_sd)\n\n      c(yy_bar, f_lo, f_hi, p_mu, b_lo, b_hi)\n    }))\n\n    list(true_mu = true_mu, y_bar = y_bar,\n         freq_lo = freq_lo, freq_hi = freq_hi,\n         post_mu = post_mu, post_sd = post_sd,\n         bayes_lo = bayes_lo, bayes_hi = bayes_hi,\n         reps = reps, prior_mu = prior_mu)\n  })\n\n  output$interval_plot &lt;- renderPlot({\n    d &lt;- dat()\n\n    par(mar = c(4.5, 8, 3, 1))\n    xlim &lt;- range(c(d$freq_lo, d$freq_hi, d$bayes_lo, d$bayes_hi, d$true_mu)) +\n            c(-0.5, 0.5)\n\n    plot(NULL, xlim = xlim, ylim = c(0.5, 2.5),\n         yaxt = \"n\", ylab = \"\", xlab = expression(mu),\n         main = \"This Experiment\")\n    axis(2, at = 1:2, labels = c(\"Frequentist\\n95% CI\", \"Bayesian\\n95% CrI\"),\n         las = 1, cex.axis = 0.85)\n\n    # Frequentist\n    segments(d$freq_lo, 1, d$freq_hi, 1, lwd = 4, col = \"#e74c3c\")\n    points(d$y_bar, 1, pch = 19, cex = 1.5, col = \"#e74c3c\")\n\n    # Bayesian\n    segments(d$bayes_lo, 2, d$bayes_hi, 2, lwd = 4, col = \"#3498db\")\n    points(d$post_mu, 2, pch = 19, cex = 1.5, col = \"#3498db\")\n\n    # True value\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n    text(d$true_mu, 2.4, expression(\"True \" * mu), cex = 0.9, col = \"#2c3e50\")\n  })\n\n  output$repeat_plot &lt;- renderPlot({\n    d &lt;- dat()\n    k &lt;- nrow(d$reps)\n\n    par(mar = c(4.5, 4, 3, 1))\n\n    freq_covers &lt;- d$reps[, 2] &lt;= d$true_mu & d$reps[, 3] &gt;= d$true_mu\n    bayes_covers &lt;- d$reps[, 5] &lt;= d$true_mu & d$reps[, 6] &gt;= d$true_mu\n\n    xlim &lt;- range(d$reps[, 2:6], d$true_mu) + c(-0.5, 0.5)\n\n    plot(NULL, xlim = xlim, ylim = c(1, k),\n         xlab = expression(mu), ylab = \"Experiment #\",\n         main = paste0(k, \" repeated experiments\"))\n\n    for (i in seq_len(k)) {\n      # Frequentist (left-shifted slightly)\n      clr_f &lt;- if (freq_covers[i]) \"#e74c3c\" else \"#e74c3c40\"\n      segments(d$reps[i, 2], i - 0.15, d$reps[i, 3], i - 0.15,\n               lwd = 1.5, col = clr_f)\n\n      # Bayesian (right-shifted slightly)\n      clr_b &lt;- if (bayes_covers[i]) \"#3498db\" else \"#3498db40\"\n      segments(d$reps[i, 5], i + 0.15, d$reps[i, 6], i + 0.15,\n               lwd = 1.5, col = clr_b)\n    }\n\n    abline(v = d$true_mu, lty = 2, lwd = 2, col = \"#2c3e50\")\n\n    legend(\"topright\", bty = \"n\", cex = 0.8,\n           legend = c(\n             paste0(\"Freq CI (\", sum(freq_covers), \"/\", k, \" cover)\"),\n             paste0(\"Bayes CrI (\", sum(bayes_covers), \"/\", k, \" cover)\")\n           ),\n           col = c(\"#e74c3c\", \"#3498db\"), lwd = 3)\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Frequentist:&lt;/b&gt;&lt;br&gt;\",\n        \"Estimate: \", round(d$y_bar, 3), \"&lt;br&gt;\",\n        \"95% CI: [\", round(d$freq_lo, 3), \", \", round(d$freq_hi, 3), \"]&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Bayesian:&lt;/b&gt;&lt;br&gt;\",\n        \"Posterior mean: \", round(d$post_mu, 3), \"&lt;br&gt;\",\n        \"95% CrI: [\", round(d$bayes_lo, 3), \", \", round(d$bayes_hi, 3), \"]&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;small&gt;CrI is narrower because the prior adds information.&lt;/small&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\n\nn = 5, prior centered at 0, true mu = 1: the Bayesian CrI is narrower but pulled toward 0 (shrinkage). The frequentist CI is wider but centered on the data.\nn = 200: both intervals are nearly identical. With lots of data, the prior washes out and Bayesian = frequentist.\nSet a wrong prior (prior mean = -3, true mu = 2, n = 5): the Bayesian interval gets pulled toward -3. A bad prior hurts with small samples. Slide n up — the data corrects it.\nRight panel: the frequentist CI is designed so that ~95% of the red intervals cover the truth across repetitions. The Bayesian CrI coverage depends on how good the prior is.\n\n\n\n\n\n\n\n\n\n\n\nUse frequentist when…\nUse Bayesian when…\n\n\n\n\nYou want procedure guarantees (coverage)\nYou want direct probability statements\n\n\nYou have no prior information\nYou have real prior knowledge\n\n\nRegulatory/peer review expects it\nSmall samples, need to borrow strength\n\n\nSimple problems\nComplex hierarchical models\n\n\n\nIn practice, most applied researchers use frequentist methods but interpret them like Bayesians. Understanding both helps you know what your numbers actually mean.",
    "crumbs": [
      "Bayesian vs Frequentist"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Bayesian Thinking",
    "section": "",
    "text": "Bayesian inference — updating beliefs with data. Start with a prior, observe data, get a posterior. Just the core logic, with simulations.\nBuilds on: Statistical Inference",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#topics",
    "href": "index.html#topics",
    "title": "Bayesian Thinking",
    "section": "Topics",
    "text": "Topics\n\nBayes’ Theorem — The engine behind everything: how evidence updates beliefs\nPriors & Posteriors — Watch your prior get overwhelmed by data\nBayesian vs Frequentist — Same question, two philosophies, different answers",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#how-does-bayesian-inference-relate-to-causal-inference",
    "href": "index.html#how-does-bayesian-inference-relate-to-causal-inference",
    "title": "Bayesian Thinking",
    "section": "How does Bayesian inference relate to causal inference?",
    "text": "How does Bayesian inference relate to causal inference?\nThey’re different questions:\n\n\n\n\n\n\n\n\n\nBayesian inference\nCausal inference\n\n\n\n\nQuestion\nWhat should I believe given the data?\nDoes X cause Y?\n\n\nFramework\nPrior + likelihood = posterior\nPotential outcomes, DAGs\n\n\nKey concept\nUpdating beliefs\nCounterfactuals\n\n\n\nYou can combine them — Bayesian causal inference uses Bayesian methods to estimate causal effects — but each stands on its own.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "shrinkage.html",
    "href": "shrinkage.html",
    "title": "Bayesian Shrinkage",
    "section": "",
    "text": "Imagine you’re a baseball scout. It’s early in the season and you need to estimate the true batting average for 50 players, each with only 20 at-bats.\nOne player went 10-for-20 (.500). Another went 1-for-20 (.050). Are those their true abilities? Probably not — with only 20 at-bats, there’s a ton of noise. The .500 hitter probably got lucky. The .050 hitter probably got unlucky.\nShrinkage says: don’t take the raw numbers at face value. Pull (“shrink”) every estimate toward the overall average. The more uncertain you are about an individual estimate, the more you pull.\n\\[\\hat{\\theta}_i^{shrunk} = w_i \\cdot \\bar{\\theta}_{overall} + (1 - w_i) \\cdot \\hat{\\theta}_i^{raw}\\]\nThis is the core of empirical Bayes and James-Stein estimation. It sounds like you’re adding bias — and you are — but you’re reducing variance by more than enough to compensate. The result: better predictions overall.\n#| standalone: true\n#| viewerHeight: 620\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n    .good { color: #27ae60; font-weight: bold; }\n    .bad  { color: #e74c3c; font-weight: bold; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"n_players\", \"Number of players:\",\n                  min = 10, max = 100, value = 40, step = 5),\n\n      sliderInput(\"at_bats\", \"At-bats per player:\",\n                  min = 5, max = 200, value = 20, step = 5),\n\n      sliderInput(\"true_spread\", \"True talent spread (SD):\",\n                  min = 0.01, max = 0.08, value = 0.03, step = 0.005),\n\n      actionButton(\"go\", \"New season\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      fluidRow(\n        column(6, plotOutput(\"shrinkage_plot\", height = \"420px\")),\n        column(6, plotOutput(\"mse_plot\", height = \"420px\"))\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n    k   &lt;- input$n_players\n    n   &lt;- input$at_bats\n    tau &lt;- input$true_spread\n\n    # True batting averages (centered around .260)\n    true_avg &lt;- rnorm(k, mean = 0.260, sd = tau)\n    true_avg &lt;- pmin(pmax(true_avg, 0.100), 0.400)\n\n    # Observed: hits in n at-bats\n    hits &lt;- rbinom(k, size = n, prob = true_avg)\n    obs_avg &lt;- hits / n\n\n    # Grand mean\n    grand_mean &lt;- mean(obs_avg)\n\n    # Empirical Bayes shrinkage\n    # Estimate prior variance from data\n    obs_var &lt;- var(obs_avg)\n    sampling_var &lt;- mean(obs_avg * (1 - obs_avg) / n)\n    prior_var &lt;- max(obs_var - sampling_var, 0.0001)\n\n    # Shrinkage weight (toward grand mean)\n    w &lt;- sampling_var / (sampling_var + prior_var)\n    shrunk_avg &lt;- w * grand_mean + (1 - w) * obs_avg\n\n    # MSE\n    mse_raw   &lt;- mean((obs_avg - true_avg)^2)\n    mse_shrunk &lt;- mean((shrunk_avg - true_avg)^2)\n\n    # Future performance (another n at-bats from true ability)\n    future_hits &lt;- rbinom(k, size = n, prob = true_avg)\n    future_avg  &lt;- future_hits / n\n\n    pred_err_raw   &lt;- mean((obs_avg - future_avg)^2)\n    pred_err_shrunk &lt;- mean((shrunk_avg - future_avg)^2)\n\n    list(true_avg = true_avg, obs_avg = obs_avg, shrunk_avg = shrunk_avg,\n         grand_mean = grand_mean, w = w,\n         mse_raw = mse_raw, mse_shrunk = mse_shrunk,\n         pred_err_raw = pred_err_raw, pred_err_shrunk = pred_err_shrunk,\n         k = k, n = n)\n  })\n\n  output$shrinkage_plot &lt;- renderPlot({\n    d &lt;- dat()\n    par(mar = c(4.5, 4.5, 3, 1))\n\n    ord &lt;- order(d$obs_avg)\n\n    plot(d$obs_avg[ord], seq_along(ord), pch = 16, col = \"#e74c3c\",\n         xlab = \"Batting average\", ylab = \"Player (sorted by raw avg)\",\n         main = \"Shrinkage in Action\",\n         xlim = range(c(d$obs_avg, d$shrunk_avg, d$true_avg)))\n\n    points(d$shrunk_avg[ord], seq_along(ord), pch = 17, col = \"#3498db\")\n    points(d$true_avg[ord], seq_along(ord), pch = 4, col = \"#27ae60\", cex = 0.8)\n\n    # Draw arrows from raw to shrunk\n    arrows(d$obs_avg[ord], seq_along(ord),\n           d$shrunk_avg[ord], seq_along(ord),\n           length = 0.05, col = \"#bdc3c780\", lwd = 1)\n\n    # Grand mean\n    abline(v = d$grand_mean, lty = 2, col = \"gray50\", lwd = 1.5)\n\n    legend(\"bottomright\", bty = \"n\", cex = 0.8,\n           legend = c(\"Raw average\", \"Shrunk estimate\",\n                      \"True ability\", \"Grand mean\"),\n           col = c(\"#e74c3c\", \"#3498db\", \"#27ae60\", \"gray50\"),\n           pch = c(16, 17, 4, NA),\n           lty = c(NA, NA, NA, 2), lwd = c(NA, NA, NA, 1.5))\n  })\n\n  output$mse_plot &lt;- renderPlot({\n    d &lt;- dat()\n    par(mar = c(4.5, 6, 3, 1))\n\n    vals &lt;- c(d$mse_raw, d$mse_shrunk, d$pred_err_raw, d$pred_err_shrunk)\n    cols &lt;- c(\"#e74c3c\", \"#3498db\", \"#e74c3c80\", \"#3498db80\")\n    labels &lt;- c(\"Raw\\nvs truth\", \"Shrunk\\nvs truth\",\n                \"Raw\\nvs future\", \"Shrunk\\nvs future\")\n\n    bp &lt;- barplot(vals, col = cols, border = NA,\n                  names.arg = labels, cex.names = 0.8,\n                  main = \"Mean Squared Error\",\n                  ylab = \"MSE\", las = 1)\n    text(bp, vals + max(vals) * 0.03, round(vals, 5), cex = 0.8)\n\n    pct1 &lt;- round((1 - d$mse_shrunk / d$mse_raw) * 100, 0)\n    pct2 &lt;- round((1 - d$pred_err_shrunk / d$pred_err_raw) * 100, 0)\n\n    mtext(paste0(\"Shrinkage reduces estimation error by ~\", pct1, \"%\"),\n          side = 1, line = 3.5, cex = 0.85, col = \"#2c3e50\")\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    pct_est &lt;- round((1 - d$mse_shrunk / d$mse_raw) * 100, 1)\n    pct_pred &lt;- round((1 - d$pred_err_shrunk / d$pred_err_raw) * 100, 1)\n\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Shrinkage weight:&lt;/b&gt; \", round(d$w * 100, 1),\n        \"% toward grand mean&lt;br&gt;\",\n        \"&lt;b&gt;Grand mean:&lt;/b&gt; \", round(d$grand_mean, 3), \"&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;MSE (raw):&lt;/b&gt; \", round(d$mse_raw, 5), \"&lt;br&gt;\",\n        \"&lt;b&gt;MSE (shrunk):&lt;/b&gt; &lt;span class='good'&gt;\",\n        round(d$mse_shrunk, 5), \"&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;b&gt;Improvement:&lt;/b&gt; &lt;span class='good'&gt;\", pct_est, \"%&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Prediction error (raw):&lt;/b&gt; \", round(d$pred_err_raw, 5), \"&lt;br&gt;\",\n        \"&lt;b&gt;Prediction error (shrunk):&lt;/b&gt; &lt;span class='good'&gt;\",\n        round(d$pred_err_shrunk, 5), \"&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;b&gt;Improvement:&lt;/b&gt; &lt;span class='good'&gt;\", pct_pred, \"%&lt;/span&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\nAt-bats = 5: extreme noise. Raw averages are all over the place (some players show .000 or .600). Shrinkage pulls them heavily toward the mean — and the green crosses (true ability) confirm the shrunk estimates are closer.\nAt-bats = 200: lots of data per player. Shrinkage is minimal because the raw averages are already precise. With enough data, shrinkage vanishes.\nLook at the MSE bars: shrinkage almost always wins, especially with small samples. It also predicts future performance better.\nTrue talent spread = 0.01 (everyone is similar): shrinkage is aggressive because individual differences are small relative to noise.\nTrue talent spread = 0.08 (wide range of talent): shrinkage is lighter because individual differences are real, not noise.",
    "crumbs": [
      "Shrinkage"
    ]
  },
  {
    "objectID": "shrinkage.html#what-is-shrinkage",
    "href": "shrinkage.html#what-is-shrinkage",
    "title": "Bayesian Shrinkage",
    "section": "",
    "text": "Imagine you’re a baseball scout. It’s early in the season and you need to estimate the true batting average for 50 players, each with only 20 at-bats.\nOne player went 10-for-20 (.500). Another went 1-for-20 (.050). Are those their true abilities? Probably not — with only 20 at-bats, there’s a ton of noise. The .500 hitter probably got lucky. The .050 hitter probably got unlucky.\nShrinkage says: don’t take the raw numbers at face value. Pull (“shrink”) every estimate toward the overall average. The more uncertain you are about an individual estimate, the more you pull.\n\\[\\hat{\\theta}_i^{shrunk} = w_i \\cdot \\bar{\\theta}_{overall} + (1 - w_i) \\cdot \\hat{\\theta}_i^{raw}\\]\nThis is the core of empirical Bayes and James-Stein estimation. It sounds like you’re adding bias — and you are — but you’re reducing variance by more than enough to compensate. The result: better predictions overall.\n#| standalone: true\n#| viewerHeight: 620\n\nlibrary(shiny)\n\nui &lt;- fluidPage(\n  tags$head(tags$style(HTML(\"\n    .stats-box {\n      background: #f0f4f8; border-radius: 6px; padding: 14px;\n      margin-top: 12px; font-size: 14px; line-height: 1.9;\n    }\n    .stats-box b { color: #2c3e50; }\n    .good { color: #27ae60; font-weight: bold; }\n    .bad  { color: #e74c3c; font-weight: bold; }\n  \"))),\n\n  sidebarLayout(\n    sidebarPanel(\n      width = 3,\n\n      sliderInput(\"n_players\", \"Number of players:\",\n                  min = 10, max = 100, value = 40, step = 5),\n\n      sliderInput(\"at_bats\", \"At-bats per player:\",\n                  min = 5, max = 200, value = 20, step = 5),\n\n      sliderInput(\"true_spread\", \"True talent spread (SD):\",\n                  min = 0.01, max = 0.08, value = 0.03, step = 0.005),\n\n      actionButton(\"go\", \"New season\", class = \"btn-primary\", width = \"100%\"),\n\n      uiOutput(\"results\")\n    ),\n\n    mainPanel(\n      width = 9,\n      fluidRow(\n        column(6, plotOutput(\"shrinkage_plot\", height = \"420px\")),\n        column(6, plotOutput(\"mse_plot\", height = \"420px\"))\n      )\n    )\n  )\n)\n\nserver &lt;- function(input, output, session) {\n\n  dat &lt;- reactive({\n    input$go\n    k   &lt;- input$n_players\n    n   &lt;- input$at_bats\n    tau &lt;- input$true_spread\n\n    # True batting averages (centered around .260)\n    true_avg &lt;- rnorm(k, mean = 0.260, sd = tau)\n    true_avg &lt;- pmin(pmax(true_avg, 0.100), 0.400)\n\n    # Observed: hits in n at-bats\n    hits &lt;- rbinom(k, size = n, prob = true_avg)\n    obs_avg &lt;- hits / n\n\n    # Grand mean\n    grand_mean &lt;- mean(obs_avg)\n\n    # Empirical Bayes shrinkage\n    # Estimate prior variance from data\n    obs_var &lt;- var(obs_avg)\n    sampling_var &lt;- mean(obs_avg * (1 - obs_avg) / n)\n    prior_var &lt;- max(obs_var - sampling_var, 0.0001)\n\n    # Shrinkage weight (toward grand mean)\n    w &lt;- sampling_var / (sampling_var + prior_var)\n    shrunk_avg &lt;- w * grand_mean + (1 - w) * obs_avg\n\n    # MSE\n    mse_raw   &lt;- mean((obs_avg - true_avg)^2)\n    mse_shrunk &lt;- mean((shrunk_avg - true_avg)^2)\n\n    # Future performance (another n at-bats from true ability)\n    future_hits &lt;- rbinom(k, size = n, prob = true_avg)\n    future_avg  &lt;- future_hits / n\n\n    pred_err_raw   &lt;- mean((obs_avg - future_avg)^2)\n    pred_err_shrunk &lt;- mean((shrunk_avg - future_avg)^2)\n\n    list(true_avg = true_avg, obs_avg = obs_avg, shrunk_avg = shrunk_avg,\n         grand_mean = grand_mean, w = w,\n         mse_raw = mse_raw, mse_shrunk = mse_shrunk,\n         pred_err_raw = pred_err_raw, pred_err_shrunk = pred_err_shrunk,\n         k = k, n = n)\n  })\n\n  output$shrinkage_plot &lt;- renderPlot({\n    d &lt;- dat()\n    par(mar = c(4.5, 4.5, 3, 1))\n\n    ord &lt;- order(d$obs_avg)\n\n    plot(d$obs_avg[ord], seq_along(ord), pch = 16, col = \"#e74c3c\",\n         xlab = \"Batting average\", ylab = \"Player (sorted by raw avg)\",\n         main = \"Shrinkage in Action\",\n         xlim = range(c(d$obs_avg, d$shrunk_avg, d$true_avg)))\n\n    points(d$shrunk_avg[ord], seq_along(ord), pch = 17, col = \"#3498db\")\n    points(d$true_avg[ord], seq_along(ord), pch = 4, col = \"#27ae60\", cex = 0.8)\n\n    # Draw arrows from raw to shrunk\n    arrows(d$obs_avg[ord], seq_along(ord),\n           d$shrunk_avg[ord], seq_along(ord),\n           length = 0.05, col = \"#bdc3c780\", lwd = 1)\n\n    # Grand mean\n    abline(v = d$grand_mean, lty = 2, col = \"gray50\", lwd = 1.5)\n\n    legend(\"bottomright\", bty = \"n\", cex = 0.8,\n           legend = c(\"Raw average\", \"Shrunk estimate\",\n                      \"True ability\", \"Grand mean\"),\n           col = c(\"#e74c3c\", \"#3498db\", \"#27ae60\", \"gray50\"),\n           pch = c(16, 17, 4, NA),\n           lty = c(NA, NA, NA, 2), lwd = c(NA, NA, NA, 1.5))\n  })\n\n  output$mse_plot &lt;- renderPlot({\n    d &lt;- dat()\n    par(mar = c(4.5, 6, 3, 1))\n\n    vals &lt;- c(d$mse_raw, d$mse_shrunk, d$pred_err_raw, d$pred_err_shrunk)\n    cols &lt;- c(\"#e74c3c\", \"#3498db\", \"#e74c3c80\", \"#3498db80\")\n    labels &lt;- c(\"Raw\\nvs truth\", \"Shrunk\\nvs truth\",\n                \"Raw\\nvs future\", \"Shrunk\\nvs future\")\n\n    bp &lt;- barplot(vals, col = cols, border = NA,\n                  names.arg = labels, cex.names = 0.8,\n                  main = \"Mean Squared Error\",\n                  ylab = \"MSE\", las = 1)\n    text(bp, vals + max(vals) * 0.03, round(vals, 5), cex = 0.8)\n\n    pct1 &lt;- round((1 - d$mse_shrunk / d$mse_raw) * 100, 0)\n    pct2 &lt;- round((1 - d$pred_err_shrunk / d$pred_err_raw) * 100, 0)\n\n    mtext(paste0(\"Shrinkage reduces estimation error by ~\", pct1, \"%\"),\n          side = 1, line = 3.5, cex = 0.85, col = \"#2c3e50\")\n  })\n\n  output$results &lt;- renderUI({\n    d &lt;- dat()\n    pct_est &lt;- round((1 - d$mse_shrunk / d$mse_raw) * 100, 1)\n    pct_pred &lt;- round((1 - d$pred_err_shrunk / d$pred_err_raw) * 100, 1)\n\n    tags$div(class = \"stats-box\",\n      HTML(paste0(\n        \"&lt;b&gt;Shrinkage weight:&lt;/b&gt; \", round(d$w * 100, 1),\n        \"% toward grand mean&lt;br&gt;\",\n        \"&lt;b&gt;Grand mean:&lt;/b&gt; \", round(d$grand_mean, 3), \"&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;MSE (raw):&lt;/b&gt; \", round(d$mse_raw, 5), \"&lt;br&gt;\",\n        \"&lt;b&gt;MSE (shrunk):&lt;/b&gt; &lt;span class='good'&gt;\",\n        round(d$mse_shrunk, 5), \"&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;b&gt;Improvement:&lt;/b&gt; &lt;span class='good'&gt;\", pct_est, \"%&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;hr style='margin:8px 0'&gt;\",\n        \"&lt;b&gt;Prediction error (raw):&lt;/b&gt; \", round(d$pred_err_raw, 5), \"&lt;br&gt;\",\n        \"&lt;b&gt;Prediction error (shrunk):&lt;/b&gt; &lt;span class='good'&gt;\",\n        round(d$pred_err_shrunk, 5), \"&lt;/span&gt;&lt;br&gt;\",\n        \"&lt;b&gt;Improvement:&lt;/b&gt; &lt;span class='good'&gt;\", pct_pred, \"%&lt;/span&gt;\"\n      ))\n    )\n  })\n}\n\nshinyApp(ui, server)\n\n\n\nAt-bats = 5: extreme noise. Raw averages are all over the place (some players show .000 or .600). Shrinkage pulls them heavily toward the mean — and the green crosses (true ability) confirm the shrunk estimates are closer.\nAt-bats = 200: lots of data per player. Shrinkage is minimal because the raw averages are already precise. With enough data, shrinkage vanishes.\nLook at the MSE bars: shrinkage almost always wins, especially with small samples. It also predicts future performance better.\nTrue talent spread = 0.01 (everyone is similar): shrinkage is aggressive because individual differences are small relative to noise.\nTrue talent spread = 0.08 (wide range of talent): shrinkage is lighter because individual differences are real, not noise.",
    "crumbs": [
      "Shrinkage"
    ]
  },
  {
    "objectID": "shrinkage.html#why-does-this-work",
    "href": "shrinkage.html#why-does-this-work",
    "title": "Bayesian Shrinkage",
    "section": "Why does this work?",
    "text": "Why does this work?\nIt seems wrong to move estimates away from the data. But consider what happens without shrinkage:\n\nPlayers who got lucky are overestimated\nPlayers who got unlucky are underestimated\nThese errors don’t cancel — they inflate the overall MSE\n\nShrinkage dampens both overestimates and underestimates simultaneously. The small bias it introduces (pulling everyone toward the mean) is more than offset by the massive reduction in variance. This is the bias-variance tradeoff in action.\n\nWhere you see this in practice\n\n\n\nMethod\nWhat gets shrunk\n\n\n\n\nRidge regression\nCoefficients toward zero\n\n\nLASSO\nCoefficients toward zero (with selection)\n\n\nRandom effects models\nGroup means toward grand mean\n\n\nEmpirical Bayes\nIndividual estimates toward overall mean\n\n\nBayesian priors\nPosteriors toward prior mean\n\n\n\nThey all share the same logic: when you have many noisy estimates, borrowing strength across them improves every single one.",
    "crumbs": [
      "Shrinkage"
    ]
  }
]